{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This project was tested using both hierarchical clustering and Random Forest Regression for \n",
    "### selecting sensors used in prediction (dimensionality reduction), but tests conducted with\n",
    "### Random Forest Regression achieve significantly better results\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'interpolated_no_na_no_noise.csv' # Constructing in sensor_cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    cols = df.columns.values\n",
    "    df_values = df[cols].values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df_values_scaled = min_max_scaler.fit_transform(df_values)\n",
    "    new_df = pd.DataFrame(index=df.index, data=df_values_scaled, columns=cols)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_euclidean_distance_between_columns(col1_values, col2_values):\n",
    "    distance = 0\n",
    "    for i in range(len(col1_values)):\n",
    "        distance += np.linalg.norm(col1_values[i] - col2_values[i])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_euclidean(df_normalized, start_index=0, similarity_matrix=False):\n",
    "    cols = df_normalized.columns.values\n",
    "    if similarity_matrix: # Checks is similarity matrix exists\n",
    "        if len(cols) > len(similarity_matrix):\n",
    "            start_index = len(similarity_matrix)\n",
    "    else:\n",
    "        similarity_matrix = []\n",
    "    for i, main_col in enumerate(cols[start_index:]):\n",
    "        \n",
    "        similarity_measures_for_col = []\n",
    "        \n",
    "        print(str(i+1) + '. ' + 'Finding similarities for column ', main_col)\n",
    "        \n",
    "        for col_to_compare in cols:\n",
    "            main_col_values = df_normalized[main_col].values\n",
    "            col_to_compare_values = df_normalized[col_to_compare].values\n",
    "            \n",
    "            distance_between_cols = calculate_euclidean_distance_between_columns(main_col_values, col_to_compare_values)\n",
    "            similarity_measures_for_col.append(distance_between_cols)\n",
    "            \n",
    "        similarity_matrix.append(similarity_measures_for_col)\n",
    "        print(similarity_measures_for_col)\n",
    "        with open('temp_similarity_matrix.pkl', 'wb') as f:\n",
    "            pickle.dump(similarity_matrix, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('interpolated_no_na_no_noise.csv', index_col=0, sep=\";\")\n",
    "df_normalized = normalize(df)\n",
    "\n",
    "euclidean_similarity_matrix = calculate_euclidean(df_normalized)\n",
    "\n",
    "with open('euclidean_similarity_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump(euclidean_similarity_matrix, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
